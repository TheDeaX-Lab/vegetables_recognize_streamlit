import numpy as np
import cv2
import streamlit as st
import pandas as pd
import time

import torch
from torchvision import transforms, models
import torch.nn as nn

num_classes = 15
model = models.resnet18(pretrained=False)
model.fc = nn.Sequential(
    nn.Linear(512, 256),
    nn.ReLU(),
    nn.BatchNorm1d(256),
    nn.Dropout(0.5),
    nn.Linear(256, num_classes)
)
model.load_state_dict(torch.load('vegetables_cnn.pth', map_location=torch.device('cpu')))  # –∏–ª–∏ 'cuda'
model.eval()

# –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ ‚Äî –º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∂–∞—Ç—å –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é)
# –ù–æ –ª—É—á—à–µ –∑–∞–≥—Ä—É–∂–∞—Ç—å –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é, —á—Ç–æ–±—ã –Ω–µ —Ç—Ä–∞—Ç–∏—Ç—å –ø–∞–º—è—Ç—å
# models = {name: load_model_by_name(name) for name in MODEL_PATHS.keys()}  # –µ—Å–ª–∏ —Ö–æ—á–µ—à—å –≤—Å–µ —Å—Ä–∞–∑—É

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤ ‚Äî –ü–û–†–Ø–î–û–ö –í–ê–ñ–ï–ù!
class_labels = list({0: '–ë–æ–±—ã', 1: '–ì–æ—Ä—å–∫–∏–π –æ–≥—É—Ä–µ—Ü', 2: '–ö–∞–±–∞—á–æ–∫', 3: '–ë–∞–∫–ª–∞–∂–∞–Ω', 4: '–ë—Ä–æ–∫–∫–æ–ª–∏', 5: '–ö–∞–ø—É—Å—Ç–∞', 6: '–°–ª–∞–¥–∫–∏–π –ø–µ—Ä–µ—Ü', 7: '–ú–æ—Ä–∫–æ–≤—å', 8: '–¶–≤–µ—Ç–Ω–∞—è –∫–∞–ø—É—Å—Ç–∞', 9: '–û–≥—É—Ä–µ—Ü', 10: '–ü–∞–ø–∞–π—è', 11: '–ö–∞—Ä—Ç–æ—Ñ–µ–ª—å', 12: '–¢—ã–∫–≤–∞', 13: '–†–µ–¥–∏—Å', 14: '–ü–æ–º–∏–¥–æ—Ä'}.values())

# =============================
# –§–£–ù–ö–¶–ò–Ø –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø (—Å –ø–µ—Ä–µ–¥–∞—á–µ–π –º–æ–¥–µ–ª–∏)
# =============================
from PIL import Image
def predict_image(image_array: np.ndarray, model) -> tuple:
    """
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç numpy-–º–∞—Å—Å–∏–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (H, W, 3) –≤ BGR –∏–ª–∏ RGB (–ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ RGB),
    –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–º–µ—Ç–∫—É, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, –≤—Å–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏).
    """
    # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ RGB (OpenCV —á–∏—Ç–∞–µ—Ç –∫–∞–∫ BGR)
    if image_array.shape[-1] == 3:
        img_rgb = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)
    else:
        img_rgb = image_array  # —É–∂–µ grayscale –∏–ª–∏ RGB

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º numpy -> PIL Image (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è transforms.ToTensor())
    pil_img = Image.fromarray(img_rgb.astype('uint8'), 'RGB')

    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º—ã (—Ç–æ—á–Ω–æ —Ç–∞–∫–∏–µ –∂–µ, –∫–∞–∫ –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏!)
    val_test_transforms = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º—ã ‚Üí –ø–æ–ª—É—á–∞–µ–º —Ç–µ–Ω–∑–æ—Ä (C, H, W)
    tensor_img = val_test_transforms(pil_img)

    # –î–æ–±–∞–≤–ª—è–µ–º batch dimension: (C, H, W) ‚Üí (1, C, H, W)
    tensor_img = tensor_img.unsqueeze(0)

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    model.eval()
    with torch.no_grad():
        outputs = model(tensor_img)
        probabilities = torch.softmax(outputs, dim=1).cpu().numpy()[0]  # [num_classes]

    # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    predicted_class_index = np.argmax(probabilities)
    confidence = probabilities[predicted_class_index]
    predicted_label = class_labels[predicted_class_index]

    return predicted_label, confidence, probabilities

# =============================
# STREAMLIT –ò–ù–¢–ï–†–§–ï–ô–°
# =============================
# –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ
st.title("ü•¶ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ–≤–æ—â–µ–π")
st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ–≤–æ—â–∞, —á—Ç–æ–±—ã –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –µ–≥–æ –≤–∏–¥.")

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –º–∞—Å—Å–∏–≤ —Å –ø–æ–º–æ—â—å—é OpenCV
    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
    image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)  # BGR —Ñ–æ—Ä–º–∞—Ç

    if image is None:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª.")
    else:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        st.image(image, channels="BGR", caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_column_width=True)

        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ..."):
            start_time = time.time()
            label, confidence, probs = predict_image(image, model)
            elapsed_time = time.time() - start_time

        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        st.info(f"**–í—Ä–µ–º—è –ø—Ä–æ–≥–Ω–æ–∑–∞**: {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥")
        st.success(f"**–û–≤–æ—â:** {label}")
        st.info(f"**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏:** {confidence:.4f}")

        # –í—ã–≤–æ–¥ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        st.write("### –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤:")
        prob_df = pd.DataFrame({
            '–û–≤–æ—â': class_labels,
            '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å': probs
        }).sort_values('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å', ascending=False).reset_index(drop=True)
        prob_df['–û–≤–æ—â'] = pd.Categorical(prob_df['–û–≤–æ—â'], categories=prob_df['–û–≤–æ—â'], ordered=True)
        st.bar_chart(prob_df.set_index('–û–≤–æ—â'))